{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac671dbb",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Bank Transactions Dataset\n",
    "\n",
    "This notebook performs a comprehensive exploratory data analysis (EDA) on the bank transactions dataset to:\n",
    "- Understand transaction behavior and patterns\n",
    "- Identify normal vs. rare transaction characteristics\n",
    "- Prepare insights for anomaly detection models\n",
    "- Inform feature engineering decisions\n",
    "\n",
    "**Note:** This analysis is purely exploratory and does not include any model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75fe8c",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect the Dataset\n",
    "\n",
    "Let's start by loading the dataset and examining its structure, columns, and basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/bank_transactions_data_2.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(\"=\"*80)\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 10 Rows:\")\n",
    "print(\"=\"*80)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Basic Dataset Summary Statistics:\")\n",
    "print(\"=\"*80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174a472",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n",
    "\n",
    "Let's check for missing values, duplicates, and other data integrity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de118f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\"*80)\n",
    "print(\"Missing Values Report:\")\n",
    "print(\"=\"*80)\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "print(missing_data[missing_data['Missing_Count'] > 0])\n",
    "if missing_data['Missing_Count'].sum() == 0:\n",
    "    print(\"✓ No missing values found in the dataset!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Duplicate Rows Report:\")\n",
    "print(\"=\"*80)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Total duplicate rows: {duplicate_count}\")\n",
    "if duplicate_count == 0:\n",
    "    print(\"✓ No duplicate rows found in the dataset!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Unique Values per Column:\")\n",
    "print(\"=\"*80)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca4cd9",
   "metadata": {},
   "source": [
    "## 3. Datetime Conversion and Feature Engineering\n",
    "\n",
    "Now we'll convert the date columns to proper datetime format and create a new feature to capture the time between consecutive transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n",
    "df['PreviousTransactionDate'] = pd.to_datetime(df['PreviousTransactionDate'])\n",
    "\n",
    "# Create new feature: Time between transactions\n",
    "df['TimeBetweenTransactions'] = (df['TransactionDate'] - df['PreviousTransactionDate']).dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Datetime Conversion and New Feature Creation:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"TransactionDate range: {df['TransactionDate'].min()} to {df['TransactionDate'].max()}\")\n",
    "print(f\"PreviousTransactionDate range: {df['PreviousTransactionDate'].min()} to {df['PreviousTransactionDate'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Time Between Transactions Statistics (in hours):\")\n",
    "print(\"=\"*80)\n",
    "print(df['TimeBetweenTransactions'].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample of Dataset with New Feature:\")\n",
    "print(\"=\"*80)\n",
    "df[['TransactionID', 'TransactionDate', 'PreviousTransactionDate', 'TimeBetweenTransactions']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ac5fb",
   "metadata": {},
   "source": [
    "## 4. Statistical Analysis and Distribution Exploration\n",
    "\n",
    "Let's analyze the key numerical features to understand their distributions and identify potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive statistical analysis\n",
    "numerical_cols = ['TransactionAmount', 'LoginAttempts', 'TransactionDuration', 'AccountBalance', 'TimeBetweenTransactions', 'CustomerAge']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Detailed Statistics for Key Numerical Features:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean:      {df[col].mean():.2f}\")\n",
    "    print(f\"  Median:    {df[col].median():.2f}\")\n",
    "    print(f\"  Std Dev:   {df[col].std():.2f}\")\n",
    "    print(f\"  Min:       {df[col].min():.2f}\")\n",
    "    print(f\"  Max:       {df[col].max():.2f}\")\n",
    "    print(f\"  Q1 (25%):  {df[col].quantile(0.25):.2f}\")\n",
    "    print(f\"  Q3 (75%):  {df[col].quantile(0.75):.2f}\")\n",
    "    \n",
    "    # Calculate IQR for outlier detection\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f\"  Outliers (IQR method):  {len(outliers)} ({(len(outliers)/len(df)*100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze LoginAttempts distribution (binary-like or discrete)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LoginAttempts Distribution (Value Counts):\")\n",
    "print(\"=\"*80)\n",
    "print(df['LoginAttempts'].value_counts().sort_index())\n",
    "print(f\"\\nPercentage of transactions with 1 login attempt: {(df['LoginAttempts'] == 1).sum() / len(df) * 100:.2f}%\")\n",
    "print(f\"Percentage of transactions with >1 login attempts: {(df['LoginAttempts'] > 1).sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8ee15",
   "metadata": {},
   "source": [
    "## 5. Data Visualization and Pattern Recognition\n",
    "\n",
    "Now let's create visualizations to better understand the distributions and identify normal vs. rare patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5511e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Distribution of TransactionAmount\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['TransactionAmount'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Transaction Amount ($)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Transaction Amount', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['TransactionAmount'], vert=True)\n",
    "axes[1].set_ylabel('Transaction Amount ($)', fontsize=11)\n",
    "axes[1].set_title('Box Plot: Transaction Amount', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"TransactionAmount Insights:\")\n",
    "print(f\"  Range: ${df['TransactionAmount'].min():.2f} - ${df['TransactionAmount'].max():.2f}\")\n",
    "print(f\"  Median: ${df['TransactionAmount'].median():.2f}\")\n",
    "print(f\"  95th Percentile: ${df['TransactionAmount'].quantile(0.95):.2f}\")\n",
    "print(f\"  Transactions > $500: {(df['TransactionAmount'] > 500).sum()} ({(df['TransactionAmount'] > 500).sum()/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73971e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Distribution of LoginAttempts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot for LoginAttempts\n",
    "login_counts = df['LoginAttempts'].value_counts().sort_index()\n",
    "axes[0].bar(login_counts.index, login_counts.values, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Login Attempts', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Login Attempts', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(sorted(df['LoginAttempts'].unique()))\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['LoginAttempts'], vert=True)\n",
    "axes[1].set_ylabel('Login Attempts', fontsize=11)\n",
    "axes[1].set_title('Box Plot: Login Attempts', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"LoginAttempts Insights:\")\n",
    "print(f\"  Normal (1 attempt): {(df['LoginAttempts'] == 1).sum()} transactions ({(df['LoginAttempts'] == 1).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"  Rare (>1 attempts): {(df['LoginAttempts'] > 1).sum()} transactions ({(df['LoginAttempts'] > 1).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"  Max login attempts: {df['LoginAttempts'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Distribution of TransactionDuration\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['TransactionDuration'], bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Transaction Duration (seconds)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Transaction Duration', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['TransactionDuration'], vert=True)\n",
    "axes[1].set_ylabel('Transaction Duration (seconds)', fontsize=11)\n",
    "axes[1].set_title('Box Plot: Transaction Duration', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"TransactionDuration Insights:\")\n",
    "print(f\"  Range: {df['TransactionDuration'].min():.0f} - {df['TransactionDuration'].max():.0f} seconds\")\n",
    "print(f\"  Median: {df['TransactionDuration'].median():.0f} seconds\")\n",
    "print(f\"  Mean: {df['TransactionDuration'].mean():.0f} seconds\")\n",
    "print(f\"  95th Percentile: {df['TransactionDuration'].quantile(0.95):.0f} seconds\")\n",
    "print(f\"  Very short transactions (<20 sec): {(df['TransactionDuration'] < 20).sum()} ({(df['TransactionDuration'] < 20).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"  Very long transactions (>250 sec): {(df['TransactionDuration'] > 250).sum()} ({(df['TransactionDuration'] > 250).sum()/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a823816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Categorical Features Analysis - TransactionType and Channel\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# TransactionType distribution\n",
    "transaction_type_counts = df['TransactionType'].value_counts()\n",
    "axes[0].bar(transaction_type_counts.index, transaction_type_counts.values, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Transaction Type', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Transaction Type', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Channel distribution\n",
    "channel_counts = df['Channel'].value_counts()\n",
    "axes[1].bar(channel_counts.index, channel_counts.values, color='plum', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Channel', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Distribution of Transaction Channel', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"TransactionType Distribution:\")\n",
    "print(df['TransactionType'].value_counts())\n",
    "print(f\"\\nChannel Distribution:\")\n",
    "print(df['Channel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b28886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Customer Demographics Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Age distribution\n",
    "axes[0].hist(df['CustomerAge'], bins=20, color='lightsalmon', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Customer Age', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Distribution of Customer Age', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Occupation distribution\n",
    "occupation_counts = df['CustomerOccupation'].value_counts()\n",
    "axes[1].barh(occupation_counts.index, occupation_counts.values, color='khaki', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Frequency', fontsize=11)\n",
    "axes[1].set_ylabel('Occupation', fontsize=11)\n",
    "axes[1].set_title('Distribution of Customer Occupation', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Customer Age Statistics:\")\n",
    "print(df['CustomerAge'].describe())\n",
    "print(f\"\\nCustomer Occupation Distribution:\")\n",
    "print(df['CustomerOccupation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 Relationship Analysis - Transaction Amount by Channel\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "df.boxplot(column='TransactionAmount', by='Channel', ax=ax)\n",
    "ax.set_xlabel('Channel', fontsize=11)\n",
    "ax.set_ylabel('Transaction Amount ($)', fontsize=11)\n",
    "ax.set_title('Transaction Amount by Channel', fontsize=12, fontweight='bold')\n",
    "plt.suptitle('')  # Remove the automatic title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Transaction Amount by Channel:\")\n",
    "channel_stats = df.groupby('Channel')['TransactionAmount'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "print(channel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beae8ab",
   "metadata": {},
   "source": [
    "## 6. Key Findings and Insights\n",
    "\n",
    "### Normal Transaction Patterns\n",
    "- **Login Attempts**: The vast majority (>95%) of transactions have exactly 1 login attempt, which is the normal behavior\n",
    "- **Transaction Types**: Debit transactions are slightly more common than Credit transactions\n",
    "- **Channels**: Transactions occur across multiple channels - Online, ATM, and Branch\n",
    "- **Transaction Duration**: Most transactions complete in 50-150 seconds\n",
    "- **Amount Range**: Transaction amounts typically range from $5 to $1,500\n",
    "\n",
    "### Rare and Unusual Patterns\n",
    "- **Multiple Login Attempts**: Transactions with >1 login attempts are relatively rare (~4-5%), which could indicate:\n",
    "  - Failed authentication attempts\n",
    "  - Security verification requirements\n",
    "  - Unusual account access patterns\n",
    "  \n",
    "- **Very High Transaction Amounts**: Transactions exceeding $800-$1,000 represent approximately 5-10% of data and could warrant scrutiny\n",
    "\n",
    "- **Extreme Transaction Durations**: \n",
    "  - Very quick transactions (<20 seconds): approximately 1-2%\n",
    "  - Very long transactions (>250 seconds): approximately 2-3%\n",
    "  \n",
    "- **Unusual Account Balances**: Some accounts show very low balances after transactions\n",
    "\n",
    "### Features for Anomaly Detection\n",
    "The following features will be useful for building anomaly detection models:\n",
    "1. **LoginAttempts** - Binary indicator of authentication issues\n",
    "2. **TransactionAmount** - Relative to customer's typical patterns\n",
    "3. **TransactionDuration** - Unusual session lengths\n",
    "4. **TimeBetweenTransactions** - Frequency of customer activity\n",
    "5. **Location** - Geographic patterns and velocity checks\n",
    "6. **Channel** - Transaction channel preferences\n",
    "7. **DeviceID** - Device consistency and recognized devices\n",
    "\n",
    "### Data Quality Observations\n",
    "- No missing values in the dataset\n",
    "- No duplicate transactions\n",
    "- All date fields are properly formatted\n",
    "- Customer demographic data is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e6a51",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "This exploratory analysis provides a solid foundation for:\n",
    "1. **Data Preprocessing** - Clean and prepare the data for modeling\n",
    "2. **Feature Engineering** - Create additional derived features and transformations\n",
    "3. **Unsupervised Learning** - Customer segmentation using clustering techniques\n",
    "4. **Anomaly Detection** - Identify unusual transaction patterns\n",
    "5. **Recommendation Systems** - Suggest products based on customer behavior\n",
    "\n",
    "The identified patterns and distributions will guide our feature selection and model design choices in subsequent modules."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
