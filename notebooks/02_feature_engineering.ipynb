{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af16d79",
   "metadata": {},
   "source": [
    "# Feature Engineering: Customer Behavior Profiles\n",
    "\n",
    "This notebook aggregates transaction-level data into customer-level behavior profiles for clustering and customer segmentation analysis.\n",
    "\n",
    "## Objective\n",
    "Transform individual transactions into meaningful customer behavior features that capture:\n",
    "- Spending patterns\n",
    "- Account activity levels\n",
    "- Login security patterns\n",
    "- Financial stability indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cceedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ad8d8",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Transaction Data\n",
    "\n",
    "Load the raw transaction data and apply preprocessing transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff553f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import preprocess_pipeline\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = Path('../data/bank_transactions_data_2.csv')\n",
    "\n",
    "print(\"Loading and preprocessing transaction data...\\n\")\n",
    "df_transactions = preprocess_pipeline(\n",
    "    filepath=data_path,\n",
    "    datetime_cols=['TransactionDate', 'PreviousTransactionDate'],\n",
    "    missing_strategy='drop'\n",
    ")\n",
    "\n",
    "print(f\"\\nTransaction data shape: {df_transactions.shape}\")\n",
    "print(f\"Number of unique customers: {df_transactions['AccountID'].nunique()}\")\n",
    "print(f\"Date range: {df_transactions['TransactionDate'].min()} to {df_transactions['TransactionDate'].max()}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of transaction data:\")\n",
    "print(df_transactions[['AccountID', 'TransactionAmount', 'TransactionDuration', \n",
    "                        'LoginAttempts', 'AccountBalance']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6109d3",
   "metadata": {},
   "source": [
    "## Step 2: Aggregate Transactions to Customer Level\n",
    "\n",
    "Transform transaction-level data into customer profiles by grouping by AccountID.\n",
    "\n",
    "### Behavioral Features Explained\n",
    "\n",
    "| Feature | Formula | Why It Matters |\n",
    "|---------|---------|---|\n",
    "| **total_transaction_amount** | Sum of all transaction amounts | Captures total spending volume; high values indicate active/wealthy customers |\n",
    "| **average_transaction_amount** | Mean of transaction amounts | Reflects typical transaction size; indicates spending patterns and risk profile |\n",
    "| **transaction_frequency** | Count of transactions | Measures customer engagement; frequent activity indicates active account usage |\n",
    "| **average_account_balance** | Mean account balance after transactions | Indicates financial stability and available funds; low balance signals risk |\n",
    "| **average_login_attempts** | Mean login attempts per transaction | Security indicator; multiple attempts suggest account access issues |\n",
    "| **std_transaction_amount** | Standard deviation of amounts | Measures spending consistency; high std indicates volatile behavior |\n",
    "| **min_account_balance** | Minimum balance observed | Risk indicator; very low balance suggests potential overdraft issues |\n",
    "| **max_account_balance** | Maximum balance observed | Wealth indicator; tracks customer's financial capacity |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AGGREGATING TRANSACTIONS TO CUSTOMER PROFILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggregate transactions to customer level\n",
    "customer_features = df_transactions.groupby('AccountID').agg({\n",
    "    'TransactionAmount': ['sum', 'mean', 'std', 'count'],\n",
    "    'AccountBalance': ['mean', 'min', 'max'],\n",
    "    'LoginAttempts': 'mean',\n",
    "    'TransactionDuration': 'mean',\n",
    "    'CustomerAge': 'first',\n",
    "    'CustomerOccupation': 'first',\n",
    "    'TransactionType': lambda x: (x == 'Debit').sum() / len(x)  # Debit ratio\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "customer_features.columns = ['_'.join(col).strip('_') for col in customer_features.columns.values]\n",
    "\n",
    "# Rename for clarity\n",
    "customer_features.rename(columns={\n",
    "    'TransactionAmount_sum': 'total_transaction_amount',\n",
    "    'TransactionAmount_mean': 'average_transaction_amount',\n",
    "    'TransactionAmount_std': 'std_transaction_amount',\n",
    "    'TransactionAmount_count': 'transaction_frequency',\n",
    "    'AccountBalance_mean': 'average_account_balance',\n",
    "    'AccountBalance_min': 'min_account_balance',\n",
    "    'AccountBalance_max': 'max_account_balance',\n",
    "    'LoginAttempts_mean': 'average_login_attempts',\n",
    "    'TransactionDuration_mean': 'average_transaction_duration',\n",
    "    'CustomerAge_first': 'customer_age',\n",
    "    'CustomerOccupation_first': 'customer_occupation',\n",
    "    'TransactionType_<lambda>': 'debit_ratio'\n",
    "}, inplace=True)\n",
    "\n",
    "# Handle any NaN values in std (occurs when customer has only 1 transaction)\n",
    "customer_features['std_transaction_amount'] = customer_features['std_transaction_amount'].fillna(0)\n",
    "\n",
    "print(f\"\\n✓ Created customer profiles for {len(customer_features)} unique customers\")\n",
    "print(f\"✓ Each row represents one customer (AccountID)\")\n",
    "print(f\"\\nFeatures created: {len(customer_features.columns)}\")\n",
    "print(f\"\\nDataframe shape: {customer_features.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Customer Profiles (first 10 customers):\")\n",
    "print(\"=\"*80)\n",
    "print(customer_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da92036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEHAVIORAL FEATURE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "behavioral_features = [\n",
    "    'total_transaction_amount',\n",
    "    'average_transaction_amount',\n",
    "    'std_transaction_amount',\n",
    "    'transaction_frequency',\n",
    "    'average_account_balance',\n",
    "    'min_account_balance',\n",
    "    'max_account_balance',\n",
    "    'average_login_attempts',\n",
    "    'average_transaction_duration',\n",
    "    'debit_ratio'\n",
    "]\n",
    "\n",
    "feature_stats = customer_features[behavioral_features].describe()\n",
    "print(feature_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633838",
   "metadata": {},
   "source": [
    "## Step 3: Feature Analysis and Correlations\n",
    "\n",
    "Analyze the relationships between behavioral features to understand customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for behavioral features\n",
    "correlation_matrix = customer_features[behavioral_features].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Create correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=0.5, cbar_kws={'label': 'Correlation'}, ax=ax)\n",
    "ax.set_title('Correlation Matrix: Customer Behavioral Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"  - Total vs Average transaction: {correlation_matrix.loc['total_transaction_amount', 'average_transaction_amount']:.3f}\")\n",
    "print(f\"  - Frequency vs Total spending: {correlation_matrix.loc['total_transaction_amount', 'transaction_frequency']:.3f}\")\n",
    "print(f\"  - Account balance measures: {correlation_matrix.loc['average_account_balance', 'max_account_balance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731d891",
   "metadata": {},
   "source": [
    "## Step 4: Normalize Features Using Standard Scaling\n",
    "\n",
    "Standardize all features to have mean=0 and std=1 for clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE NORMALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a copy for scaled features\n",
    "customer_features_scaled = customer_features.copy()\n",
    "\n",
    "# Scale only behavioral features\n",
    "X_scaled = scaler.fit_transform(customer_features[behavioral_features])\n",
    "\n",
    "# Replace original values with scaled values\n",
    "customer_features_scaled[behavioral_features] = X_scaled\n",
    "\n",
    "print(f\"\\n✓ Scaled {len(behavioral_features)} behavioral features using StandardScaler\")\n",
    "print(f\"✓ Each feature now has mean≈0 and std≈1\")\n",
    "\n",
    "print(\"\\nBefore Scaling (original):\")\n",
    "print(customer_features[behavioral_features].describe().round(2))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"After Scaling (normalized):\")\n",
    "print(customer_features_scaled[behavioral_features].describe().round(2))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Sample: Original vs Scaled (first 5 customers)\")\n",
    "print(\"-\"*80)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Customer': customer_features['AccountID'].head(5).values,\n",
    "    'Total_Amt_Original': customer_features['total_transaction_amount'].head(5).values,\n",
    "    'Total_Amt_Scaled': customer_features_scaled['total_transaction_amount'].head(5).values,\n",
    "    'Avg_Attempts_Original': customer_features['average_login_attempts'].head(5).values,\n",
    "    'Avg_Attempts_Scaled': customer_features_scaled['average_login_attempts'].head(5).values,\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79332e",
   "metadata": {},
   "source": [
    "## Step 5: Final Dataset Summary\n",
    "\n",
    "Prepare the final customer profile dataset ready for clustering and segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL CUSTOMER PROFILE DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDataset Dimensions:\")\n",
    "print(f\"  Customers (rows): {len(customer_features_scaled)}\")\n",
    "print(f\"  Total Features (cols): {len(customer_features_scaled.columns)}\")\n",
    "print(f\"  Behavioral Features (for clustering): {len(behavioral_features)}\")\n",
    "print(f\"  Metadata Features: {len(customer_features_scaled.columns) - len(behavioral_features)}\")\n",
    "\n",
    "print(f\"\\nColumns in Final Dataset:\")\n",
    "print(f\"  Behavioral: {behavioral_features}\")\n",
    "print(f\"  Metadata: {[col for col in customer_features_scaled.columns if col not in behavioral_features]}\")\n",
    "\n",
    "print(f\"\\nData Types:\")\n",
    "print(customer_features_scaled.dtypes)\n",
    "\n",
    "print(f\"\\nNo missing values: {customer_features_scaled.isnull().sum().sum() == 0}\")\n",
    "print(f\"No duplicate rows: {customer_features_scaled.duplicated().sum() == 0}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"READY FOR CLUSTERING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Transformed {len(df_transactions)} transactions into {len(customer_features_scaled)} customer profiles\")\n",
    "print(f\"✓ Features are normalized and ready for machine learning\")\n",
    "print(f\"✓ Customer identifiers (AccountID) preserved for tracking\")\n",
    "print(f\"✓ No sensitive or personally identifiable information exposed\")\n",
    "\n",
    "# Display final dataset sample\n",
    "print(\"\\nFinal Customer Profile (first 5 customers, scaled features):\")\n",
    "print(customer_features_scaled[['AccountID'] + behavioral_features[:5]].head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
